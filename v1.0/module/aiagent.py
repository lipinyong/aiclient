import re
import json
import asyncio
import logging
from typing import AsyncGenerator, Dict, Any, Optional, List
from pathlib import Path

import httpx
from openai import AsyncOpenAI

logger = logging.getLogger(__name__)

# ============ [æ–°å¢] Tokenä¼°ç®—å¸¸é‡ ============
CHARS_PER_TOKEN = 2.5  # å¹³å‡æ¯ä¸ªtokençº¦2.5ä¸ªå­—ç¬¦
MAX_TOOL_RESULT_TOKENS = 80000  # è§¦å‘è‡ªåŠ¨åˆ†å—çš„é˜ˆå€¼


# ============ [æ–°å¢] Tokenä¼°ç®—å‡½æ•° ============
def estimate_tokens(text: str) -> int:
    """ä¼°ç®—æ–‡æœ¬çš„tokenæ•°é‡"""
    return int(len(text) / CHARS_PER_TOKEN)


def clean_utf8(text: str) -> str:
    """æ¸…ç†å­—ç¬¦ä¸²ä¸­çš„æ— æ•ˆUTF-8å­—ç¬¦"""
    if not isinstance(text, str):
        return text
    # ç§»é™¤ä»£ç†å¯¹å’Œå…¶ä»–æ— æ•ˆUTF-8å­—ç¬¦
    return ''.join(c for c in text if c.isprintable() or c in '\n\r\t')

def redact_sensitive_data(data: Any, sensitive_keys: set = None) -> Any:
    """é€’å½’å±è”½æ•æ„Ÿæ•°æ®"""
    if sensitive_keys is None:
        sensitive_keys = {'access_token', 'token', 'password', 'secret', 'api_key'}
    
    if isinstance(data, dict):
        result = {}
        for key, value in data.items():
            if key.lower() in sensitive_keys or any(sk in key.lower() for sk in sensitive_keys):
                result[key] = '***REDACTED***'
            else:
                result[key] = redact_sensitive_data(value, sensitive_keys)
        return result
    elif isinstance(data, list):
        return [redact_sensitive_data(item, sensitive_keys) for item in data]
    elif isinstance(data, str):
        if len(data) > 50 and any(c.isalnum() for c in data):
            for sk in sensitive_keys:
                if sk in data.lower():
                    return '***REDACTED***'
        return clean_utf8(data)
    else:
        return data


class AIAgent:
    def __init__(self, config: Dict[str, Any], mcp_manager=None, user_info: Dict[str, Any] = None):
        self.config = config
        self.provider = config.get('provider', 'deepseek')
        
        providers = config.get('providers', {})
        provider_config = providers.get(self.provider, {})
        
        self.base_url = provider_config.get('base_url', 'https://api.deepseek.com')
        self.api_key = provider_config.get('api_key', '')
        self.model = provider_config.get('model', 'deepseek-chat')
        self.temperature = provider_config.get('temperature', config.get('temperature', 0.7))
        self.max_tokens = provider_config.get('max_tokens', config.get('max_tokens', 4096))
        self.max_iterations = config.get('max_iterations', 100)  # å·¥å…·è°ƒç”¨æœ€å¤§è¿­ä»£æ¬¡æ•°
        self.mcp_manager = mcp_manager
        self.user_info = user_info or {}
        
        # Token ç»Ÿè®¡
        self.token_stats = {
            "prompt_tokens": 0,
            "completion_tokens": 0,
            "total_tokens": 0,
            "api_calls": 0,
            "tool_calls": 0,
            "current_prompt": ""
        }
        
        self.client = AsyncOpenAI(
            api_key=self.api_key,
            base_url=self.base_url
        )
    
    def reset_token_stats(self, prompt: str = ""):
        """é‡ç½® token ç»Ÿè®¡"""
        import time
        self.token_stats = {
            "prompt_tokens": 0,
            "completion_tokens": 0,
            "total_tokens": 0,
            "api_calls": 0,
            "tool_calls": 0,
            "current_prompt": prompt,
            "start_time": time.time(),
            "elapsed_seconds": 0
        }
    
    def get_token_stats(self) -> Dict[str, Any]:
        """è·å– token ç»Ÿè®¡ä¿¡æ¯"""
        return self.token_stats.copy()
    
    def get_tools(self, service_names: Optional[List[str]] = None) -> List[Dict[str, Any]]:
        """è·å–å·¥å…·å®šä¹‰ã€‚å½“ service_names æŒ‡å®šæ—¶ä»…è¿”å›å¯¹åº” skill çš„å·¥å…·ï¼ˆæŒ‰éœ€æäº¤ï¼‰ã€‚"""
        if not self.mcp_manager:
            return []

        # å·¥å…·åå‰ç¼€ -> æœåŠ¡åï¼ˆç”¨äºæŒ‰ skill è¿‡æ»¤ï¼‰
        # dataproc_* -> data_processorï¼Œå…¶ä½™æœåŠ¡å‰ç¼€å³æœåŠ¡å
        prefix_to_service: Dict[str, str] = {}
        for s in self.mcp_manager.services:
            prefix_to_service[s] = s
        for prefix, svc in self.SERVICE_ALIASES.items():
            prefix_to_service[prefix] = svc

        tools = []
        for service_name, service in self.mcp_manager.services.items():
            if service_names is not None and len(service_names) > 0 and service_name not in service_names:
                continue
            defs = []
            if hasattr(service.module, 'TOOL_DEFINITIONS'):
                defs = list(service.module.TOOL_DEFINITIONS)
            elif hasattr(service.module, 'get_tool_definitions'):
                defs = list(service.module.get_tool_definitions())
            for d in defs:
                fn = d.get("function") or {}
                name = fn.get("name") if isinstance(fn, dict) else None
                if not name:
                    tools.append(d)
                    continue
                prefix = name.split("_", 1)[0]
                tool_service = prefix_to_service.get(prefix, prefix)
                if service_names is None or len(service_names) == 0 or tool_service in service_names:
                    tools.append(d)
        return tools
    
    # ============ [æ–°å¢] æœåŠ¡åˆ«åæ˜ å°„ ============
    # è§£å†³å·¥å…·åç§°å‰ç¼€ "dataproc_" ä¸æœåŠ¡å "data_processor" ä¸åŒ¹é…çš„é—®é¢˜
    SERVICE_ALIASES = {
        "dataproc": "data_processor",
    }
    
    async def execute_tool(self, tool_name: str, arguments: Dict[str, Any]) -> Any:
        if not self.mcp_manager:
            return {"error": "MCPç®¡ç†å™¨æœªé…ç½®"}
        
        parts = tool_name.split('_', 1)
        if len(parts) < 2:
            return {"error": f"æ— æ•ˆçš„å·¥å…·åç§°: {tool_name}"}
        
        service_name = parts[0]
        # ============ [æ–°å¢] åº”ç”¨æœåŠ¡åˆ«åæ˜ å°„ ============
        service_name = self.SERVICE_ALIASES.get(service_name, service_name)
        func_name = parts[1]
        
        service = self.mcp_manager.get_service(service_name)
        if not service:
            return {"error": f"MCPæœåŠ¡ä¸å­˜åœ¨: {service_name}"}
        
        if func_name not in service.tools:
            return {"error": f"å·¥å…·ä¸å­˜åœ¨: {func_name}"}
        
        try:
            # éªŒè¯å¿…å¡«å‚æ•°
            tool_func = service.tools.get(func_name)
            if tool_func:
                import inspect
                sig = inspect.signature(tool_func)
                required_params = [
                    p.name for p in sig.parameters.values() 
                    if p.default == inspect.Parameter.empty and p.name not in ('self', 'kwargs')
                ]
                missing = [p for p in required_params if p not in arguments]
                if missing:
                    return {"error": f"ç¼ºå°‘å¿…å¡«å‚æ•°: {', '.join(missing)}ã€‚è¯·æä¾›å®Œæ•´å‚æ•°åé‡è¯•ã€‚"}
            
            if func_name == 'save_weekly_report':
                if 'access_token' not in arguments or not arguments.get('access_token'):
                    arguments['access_token'] = self.user_info.get('external_token', '') if self.user_info else ''
                if 'username' not in arguments or not arguments.get('username'):
                    arguments['username'] = self.user_info.get('username', '') if self.user_info else ''
            
            if func_name == 'send_email' and service_name == 'mail':
                to_addr = arguments.get('to', '')
                if to_addr.lower() in ['me', 'æˆ‘', 'myself', 'è‡ªå·±']:
                    user_email = self.user_info.get('email', '') if self.user_info else ''
                    if user_email:
                        arguments['to'] = user_email
                        arguments['_replaced_to'] = f"{to_addr} -> {user_email}"
                        logger.info(f"é‚®ä»¶æ”¶ä»¶äººæ›¿æ¢: {to_addr} -> {user_email}")
                    else:
                        return {"error": "æ— æ³•å‘é€é‚®ä»¶ç»™è‡ªå·±ï¼šæœªæ‰¾åˆ°å½“å‰ç”¨æˆ·çš„é‚®ç®±åœ°å€ï¼Œè¯·ç™»å½•åé‡è¯•æˆ–åœ¨è®¾ç½®ä¸­é…ç½®é‚®ç®±"}
            
            result = await service.call_tool(func_name, **arguments)
            return result
        except Exception as e:
            logger.error(f"å·¥å…·æ‰§è¡Œå¤±è´¥: {e}")
            return {"error": str(e)}
    
    # ============ [æ–°å¢] æ¶ˆæ¯å†å²å‹ç¼©æ–¹æ³• ============
    def _compress_messages_if_needed(self, messages: List[Dict], max_tokens: int) -> List[Dict]:
        """å½“æ¶ˆæ¯å†å²è¿‡é•¿æ—¶ï¼Œå‹ç¼©æ—§çš„å·¥å…·ç»“æœ
        
        ç­–ç•¥ï¼šä¿ç•™ç³»ç»Ÿæ¶ˆæ¯å’Œç”¨æˆ·æ¶ˆæ¯ï¼Œå°†å¤§çš„å·¥å…·ç»“æœæ›¿æ¢ä¸ºæ‘˜è¦
        """
        total_tokens = sum(estimate_tokens(json.dumps(m, ensure_ascii=False)) for m in messages)
        
        if total_tokens <= max_tokens:
            return messages
        
        logger.info(f"æ¶ˆæ¯å†å²è¿‡é•¿ ({total_tokens} tokens)ï¼Œå¼€å§‹å‹ç¼©...")
        
        compressed = []
        for i, msg in enumerate(messages):
            if msg["role"] == "tool":
                content = msg.get("content", "")
                content_tokens = estimate_tokens(content)
                
                # å¦‚æœå·¥å…·ç»“æœè¶…è¿‡ 10000 tokensï¼Œå‹ç¼©å®ƒ
                if content_tokens > 10000:
                    try:
                        result = json.loads(content)
                        # åˆ›å»ºå‹ç¼©æ‘˜è¦
                        if isinstance(result, dict):
                            if "content" in result:
                                # dataproc_get_chunk ç»“æœï¼Œåªä¿ç•™å…ƒä¿¡æ¯
                                summary = {
                                    "compressed": True,
                                    "original_tokens": content_tokens,
                                    "chunk_id": result.get("chunk_id", ""),
                                    "char_count": result.get("char_count", 0),
                                    "info": result.get("info", {}),
                                    "note": "å†…å®¹å·²å‹ç¼©ï¼Œå¦‚éœ€é‡æ–°æŸ¥çœ‹è¯·å†æ¬¡è°ƒç”¨ dataproc_get_chunk"
                                }
                            else:
                                # å…¶ä»–å·¥å…·ç»“æœï¼Œä¿ç•™é”®å
                                summary = {
                                    "compressed": True,
                                    "original_tokens": content_tokens,
                                    "keys": list(result.keys())[:10],
                                    "note": "ç»“æœå·²å‹ç¼©"
                                }
                        else:
                            summary = {
                                "compressed": True,
                                "original_tokens": content_tokens,
                                "type": type(result).__name__,
                                "note": "ç»“æœå·²å‹ç¼©"
                            }
                        compressed.append({
                            "role": "tool",
                            "tool_call_id": msg.get("tool_call_id", ""),
                            "content": json.dumps(summary, ensure_ascii=False)
                        })
                        logger.info(f"å‹ç¼©å·¥å…·ç»“æœ: {content_tokens} -> {estimate_tokens(json.dumps(summary))} tokens")
                        continue
                    except:
                        pass
            
            compressed.append(msg)
        
        new_total = sum(estimate_tokens(json.dumps(m, ensure_ascii=False)) for m in compressed)
        logger.info(f"æ¶ˆæ¯å‹ç¼©å®Œæˆ: {total_tokens} -> {new_total} tokens")
        
        return compressed
    
    # ============ [æ–°å¢] å¤§æ•°æ®è‡ªåŠ¨åˆ†å—æ–¹æ³• ============
    async def _auto_chunk_large_result(self, result_json: str, tool_name: str) -> Dict[str, Any]:
        """è‡ªåŠ¨å°†å¤§ç»“æœåˆ†å—å¤„ç†
        
        å½“å·¥å…·è¿”å›ç»“æœè¶…è¿‡ MAX_TOOL_RESULT_TOKENS æ—¶è°ƒç”¨æ­¤æ–¹æ³•ï¼Œ
        ä½¿ç”¨ data_processor æœåŠ¡å°†æ•°æ®åˆ†å—ï¼Œé¿å…ä¸Šä¸‹æ–‡é•¿åº¦è¶…é™ã€‚
        """
        try:
            data_processor = self.mcp_manager.get_service("data_processor") if self.mcp_manager else None
            
            if data_processor and hasattr(data_processor.module, 'chunk_text'):
                chunk_result = await data_processor.module.chunk_text(result_json, source=tool_name)
                
                if chunk_result.get("success"):
                    chunks = chunk_result.get("chunks", [])
                    chunk_ids = [c["chunk_id"] for c in chunks]
                    
                    # ä¿å­˜ä»»åŠ¡çŠ¶æ€ï¼Œæ–¹ä¾¿åç»­ç»§ç»­å¤„ç†
                    if hasattr(data_processor.module, '_save_task_state'):
                        import hashlib
                        task_id = hashlib.md5(f"{tool_name}_{len(chunks)}".encode()).hexdigest()[:8]
                        data_processor.module._save_task_state(
                            task_id=task_id,
                            chunk_ids=chunk_ids,
                            processed_ids=[],
                            description=f"æ¥è‡ª {tool_name} çš„æ•°æ®å¤„ç†ä»»åŠ¡",
                            source=tool_name
                        )
                    
                    instructions = f"""
æ•°æ®é‡è¿‡å¤§ï¼Œå·²è‡ªåŠ¨åˆ†å—å¤„ç†ã€‚

ğŸ“Š åˆ†å—ç»Ÿè®¡:
- æ€»æ•°æ®å—: {len(chunks)} ä¸ª
- ä¼°è®¡æ€»Tokenæ•°: {chunk_result.get('total_estimated_tokens', 0)}

ğŸ“‹ å¤„ç†æ­¥éª¤ï¼ˆå¿…é¡»å¤„ç†å…¨éƒ¨ {len(chunks)} ä¸ªæ•°æ®å—ï¼ï¼‰:
1. è°ƒç”¨ dataproc_get_next_chunk è·å–ä¸‹ä¸€ä¸ªæœªå¤„ç†çš„æ•°æ®å—
2. åˆ†ææ•°æ®å—å†…å®¹ï¼Œè°ƒç”¨ dataproc_save_summary ä¿å­˜æ‘˜è¦ï¼ˆä¼šè‡ªåŠ¨æ ‡è®°ä¸ºå·²å¤„ç†ï¼‰
3. é‡å¤æ­¥éª¤1-2ç›´åˆ°æ‰€æœ‰ {len(chunks)} ä¸ªæ•°æ®å—å…¨éƒ¨å¤„ç†å®Œæ¯•
4. æœ€åè°ƒç”¨ dataproc_merge_summaries åˆå¹¶æ‰€æœ‰æ‘˜è¦ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š

âš ï¸ é‡è¦ï¼šå¿…é¡»å¤„ç†å…¨éƒ¨ {len(chunks)} ä¸ªæ•°æ®å—ï¼Œä¸èƒ½æå‰åœæ­¢ï¼

ğŸ”– æ•°æ®å—ID (å‰5ä¸ª):
{chr(10).join([f"  - {cid}" for cid in chunk_ids[:5]])}
{'  ... è¿˜æœ‰ ' + str(len(chunk_ids) - 5) + ' ä¸ªæ•°æ®å—' if len(chunk_ids) > 5 else ''}

è¯·ç«‹å³å¼€å§‹å¤„ç†ç¬¬ä¸€ä¸ªæ•°æ®å—ã€‚
"""
                    return {
                        "success": True,
                        "chunked": True,
                        "total_chunks": len(chunks),
                        "chunk_ids": chunk_ids,
                        "instructions": instructions
                    }
            
            # é™çº§å¤„ç†ï¼šç›´æ¥æˆªæ–­
            truncated = result_json[:50000] + f"\n\n... [æ•°æ®è¿‡å¤§ï¼Œå·²æˆªæ–­ï¼ŒåŸå§‹é•¿åº¦: {len(result_json)} å­—ç¬¦]"
            return {
                "success": True,
                "chunked": False,
                "truncated": True,
                "data": truncated,
                "message": "æ•°æ®è¿‡å¤§å·²æˆªæ–­ï¼Œå»ºè®®ä½¿ç”¨åˆ†å—å¤„ç†"
            }
        except Exception as e:
            logger.error(f"è‡ªåŠ¨åˆ†å—å¤±è´¥: {e}")
            truncated = result_json[:50000] + f"\n\n... [æˆªæ–­ï¼Œé”™è¯¯: {str(e)}]"
            return {"success": False, "error": str(e), "data": truncated}
    
    async def chat(self, prompt: str, stream: bool = True, skills: Optional[List[str]] = None) -> AsyncGenerator[Dict[str, Any], None]:
        import time
        start_time = time.time()
        try:
            if stream:
                async for chunk in self._stream_chat_with_tools(prompt, skills=skills):
                    yield chunk
            else:
                result = await self._sync_chat_with_tools(prompt, skills=skills)
                yield result
        except Exception as e:
            logger.error(f"AIèŠå¤©é”™è¯¯: {e}", exc_info=True)
            # ç¡®ä¿é”™è¯¯æ—¶ä¹Ÿè¿”å›ç»Ÿè®¡ä¿¡æ¯
            self.token_stats["elapsed_seconds"] = time.time() - self.token_stats.get("start_time", start_time)
            self.token_stats["total_tokens"] = self.token_stats["prompt_tokens"] + self.token_stats["completion_tokens"]
            yield {"type": "error", "content": str(e), "token_stats": self.token_stats.copy()}
    
    async def _stream_chat_with_tools(self, prompt: str, skills: Optional[List[str]] = None) -> AsyncGenerator[Dict[str, Any], None]:
        # é‡ç½® token ç»Ÿè®¡
        self.reset_token_stats(prompt)
        
        user_context = ""
        if self.user_info:
            username = self.user_info.get('username', '')
            cname = self.user_info.get('cname', '')
            if username:
                user_context = f"\n\nå½“å‰ç™»å½•ç”¨æˆ·: {cname or username} (ç”¨æˆ·å: {username})ã€‚ç”¨æˆ·çš„access_tokenå·²è‡ªåŠ¨è·å–ï¼Œè°ƒç”¨éœ€è¦è®¤è¯çš„å·¥å…·æ—¶æ— éœ€å†è¯¢é—®ç”¨æˆ·æä¾›tokenã€‚"
        
        # ç³»ç»Ÿæç¤º
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·å®Œæˆä»»åŠ¡ã€‚

é‡è¦è§„åˆ™ï¼š
1. å½“éœ€è¦æŸ¥è¯¢æ•°æ®æˆ–æäº¤æŠ¥å‘Šæ—¶ï¼Œè¯·ç›´æ¥ä½¿ç”¨æä¾›çš„å·¥å…·ï¼Œä¸è¦è¯¢é—®ç”¨æˆ·æä¾›access_tokenç­‰è®¤è¯ä¿¡æ¯ï¼Œè¿™äº›ä¿¡æ¯ä¼šè‡ªåŠ¨æ³¨å…¥ã€‚
2. ã€å¼ºåˆ¶è¦æ±‚ã€‘å½“æ•°æ®è¢«åˆ†å—å¤„ç†æ—¶ï¼ˆæ”¶åˆ°chunk_idsåˆ—è¡¨ï¼‰ï¼Œä½ å¿…é¡»å¤„ç†å…¨éƒ¨æ•°æ®å—ï¼Œç»å¯¹ä¸èƒ½è·³è¿‡ä»»ä½•å—ï¼
   - æ”¶åˆ°Nä¸ªchunk_idsï¼Œå°±å¿…é¡»è°ƒç”¨Næ¬¡dataproc_get_chunkè·å–æ¯ä¸ªå—
   - æ¯è·å–ä¸€ä¸ªå—åï¼Œåˆ†æå†…å®¹å¹¶è°ƒç”¨dataproc_save_summaryä¿å­˜æ‘˜è¦
   - æŒç»­å¤„ç†ç›´åˆ°æ‰€æœ‰å—éƒ½å®Œæˆï¼Œä¸è¦ä¸­é€”åœæ­¢
3. æ‰€æœ‰å—å¤„ç†å®Œæˆåï¼Œè°ƒç”¨dataproc_get_all_summariesè·å–æ‰€æœ‰æ‘˜è¦ï¼Œç„¶åç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šã€‚
4. å¦‚æœç”¨æˆ·è¦æ±‚å¤„ç†"æ‰€æœ‰"æ•°æ®æˆ–"å…¨å¹´"æ•°æ®ï¼Œä½ å¿…é¡»å¤„ç†100%çš„æ•°æ®å—ï¼Œä¸èƒ½å› ä¸º"æ ·æœ¬è¶³å¤Ÿ"è€Œæå‰åœæ­¢ã€‚
5. ã€é‡è¦ã€‘ç”ŸæˆæŠ¥å‘Šæ—¶å¿…é¡»è¦†ç›–æ•°æ®çš„å®Œæ•´æ—¶é—´èŒƒå›´ï¼ˆå¦‚1æœˆ-12æœˆï¼‰ï¼Œä¸èƒ½åªè¾“å‡ºéƒ¨åˆ†æœˆä»½çš„å†…å®¹ã€‚æ‰€æœ‰æ‘˜è¦éƒ½è¦æ•´åˆåˆ°æœ€ç»ˆæŠ¥å‘Šä¸­ã€‚
6. å›ç­”æ—¶è¯·ä½¿ç”¨ä¸­æ–‡ã€‚{user_context}"""
        
        # æ¸…ç†ç”¨æˆ·è¾“å…¥ä¸­çš„æ— æ•ˆUTF-8å­—ç¬¦
        cleaned_prompt = clean_utf8(prompt)
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": cleaned_prompt}
        ]
        
        tools = self.get_tools(service_names=skills)
        max_iterations = self.max_iterations  # ä»é…ç½®è¯»å–
        iteration = 0
        
        # æ¶ˆæ¯å†å² token é™åˆ¶ï¼ˆç•™å‡ºç©ºé—´ç»™æ–°å†…å®¹å’Œå›å¤ï¼‰
        MAX_HISTORY_TOKENS = 80000
        
        while iteration < max_iterations:
            iteration += 1
            
            # ============ [æ–°å¢] æ¶ˆæ¯å†å²å‹ç¼© ============
            messages = self._compress_messages_if_needed(messages, MAX_HISTORY_TOKENS)
            # ============ [æ–°å¢ç»“æŸ] ============
            
            # ============ [æ–°å¢] API è°ƒç”¨é‡è¯•æœºåˆ¶ ============
            max_retries = 3
            retry_delay = 2
            last_error = None
            stream_response = None
            
            for retry in range(max_retries):
                try:
                    if tools:
                        stream_response = await self.client.chat.completions.create(
                            model=self.model,
                            messages=messages,
                            temperature=self.temperature,
                            max_tokens=self.max_tokens,
                            tools=tools,
                            tool_choice="auto",
                            stream=True
                        )
                    else:
                        stream_response = await self.client.chat.completions.create(
                            model=self.model,
                            messages=messages,
                            temperature=self.temperature,
                            max_tokens=self.max_tokens,
                            stream=True
                        )
                    break  # æˆåŠŸåˆ™è·³å‡ºé‡è¯•å¾ªç¯
                except Exception as e:
                    last_error = e
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸ºä¸å¯é‡è¯•çš„é”™è¯¯ç±»å‹
                    # ä½¿ç”¨å¼‚å¸¸ç±»å‹æ£€æŸ¥ï¼ˆæ›´å¯é ï¼‰å’Œå­—ç¬¦ä¸²æ£€æŸ¥ï¼ˆå…œåº•ï¼‰
                    is_non_retryable = False
                    
                    # æ£€æŸ¥ OpenAI SDK çš„ BadRequestError (400 é”™è¯¯)
                    error_class_name = type(e).__name__
                    if error_class_name in ('BadRequestError', 'InvalidRequestError', 'AuthenticationError', 'PermissionDeniedError'):
                        is_non_retryable = True
                    
                    # å…œåº•ï¼šæ£€æŸ¥é”™è¯¯æ¶ˆæ¯ä¸­çš„å…³é”®è¯
                    error_str = str(e).lower()
                    if any(kw in error_str for kw in ['invalid_request', 'maximum context length', 'authentication', 'permission denied']):
                        is_non_retryable = True
                    
                    # æ£€æŸ¥ HTTP çŠ¶æ€ç ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    if hasattr(e, 'status_code') and e.status_code in (400, 401, 403, 404):
                        is_non_retryable = True
                    
                    if is_non_retryable:
                        logger.error(f"APIè¯·æ±‚é”™è¯¯ï¼ˆä¸å¯é‡è¯•ï¼‰: {e}")
                        raise last_error
                    
                    # å¯é‡è¯•çš„é”™è¯¯ï¼ˆç½‘ç»œè¶…æ—¶ã€è¿æ¥é”™è¯¯ç­‰ï¼‰
                    if retry < max_retries - 1:
                        logger.warning(f"APIè°ƒç”¨å¤±è´¥ï¼Œ{retry_delay}ç§’åé‡è¯• ({retry + 1}/{max_retries}): {e}")
                        yield {
                            "type": "process_info",
                            "message": f"ç½‘ç»œè¿æ¥ä¸­æ–­ï¼Œ{retry_delay}ç§’åé‡è¯•..."
                        }
                        import asyncio
                        await asyncio.sleep(retry_delay)
                        retry_delay *= 2  # æŒ‡æ•°é€€é¿
                    else:
                        raise last_error
            # ============ [æ–°å¢ç»“æŸ] ============
            
            collected_content = ""
            collected_tool_calls = {}
            thinking_content = ""
            say_content = ""
            in_thinking = False
            has_tool_calls = False
            stream_error = None
            
            # æ›´æ–° API è°ƒç”¨ç»Ÿè®¡
            self.token_stats["api_calls"] += 1
            # ä¼°ç®—å½“å‰æ¶ˆæ¯çš„ token æ•°ï¼ˆä»…ä¼°ç®—ï¼Œä¸ä» API è·å–ï¼‰
            messages_tokens = estimate_tokens(json.dumps(messages, ensure_ascii=False))
            self.token_stats["prompt_tokens"] += messages_tokens
            
            try:
                async for chunk in stream_response:
                    if not chunk.choices:
                        continue
                        
                    delta = chunk.choices[0].delta
                    
                    if delta.tool_calls:
                        has_tool_calls = True
                        for tc in delta.tool_calls:
                            idx = tc.index
                            if idx not in collected_tool_calls:
                                collected_tool_calls[idx] = {
                                    "id": "",
                                    "name": "",
                                    "arguments": ""
                                }
                            if tc.id:
                                collected_tool_calls[idx]["id"] = tc.id
                            if tc.function:
                                if tc.function.name:
                                    collected_tool_calls[idx]["name"] = tc.function.name
                                if tc.function.arguments:
                                    collected_tool_calls[idx]["arguments"] += tc.function.arguments
                    
                    if delta.content:
                        content = delta.content
                        collected_content += content
                        
                        if "<think>" in content:
                            in_thinking = True
                            content = content.replace("<think>", "")
                        
                        if "</think>" in content:
                            in_thinking = False
                            parts = content.split("</think>")
                            if len(parts) > 0:
                                thinking_content += parts[0]
                            if len(parts) > 1 and parts[1]:
                                say_content += parts[1]
                                yield {"type": "say", "content": parts[1], "partial": True}
                            continue
                        
                        if in_thinking:
                            thinking_content += content
                            yield {"type": "think", "content": content, "partial": True}
                        else:
                            say_content += content
                            yield {"type": "say", "content": content, "partial": True}
            except Exception as e:
                stream_error = e
                logger.error(f"æµå¼è¯»å–é”™è¯¯: {e}")
                yield {
                    "type": "error",
                    "message": f"ç½‘ç»œè¿æ¥ä¸­æ–­ï¼Œè¯·è¾“å…¥'ç»§ç»­'é‡è¯•"
                }
                return
            
            if has_tool_calls and collected_tool_calls:
                tool_calls_list = []
                for idx in sorted(collected_tool_calls.keys()):
                    tc_data = collected_tool_calls[idx]
                    tool_calls_list.append({
                        "id": tc_data["id"],
                        "type": "function",
                        "function": {
                            "name": tc_data["name"],
                            "arguments": tc_data["arguments"]
                        }
                    })
                
                messages.append({
                    "role": "assistant",
                    "content": collected_content or "",
                    "tool_calls": tool_calls_list
                })
                
                for tc_data in tool_calls_list:
                    tool_name = tc_data["function"]["name"]
                    try:
                        arguments = json.loads(tc_data["function"]["arguments"])
                    except:
                        arguments = {}
                    
                    # æ›´æ–°å·¥å…·è°ƒç”¨ç»Ÿè®¡
                    self.token_stats["tool_calls"] += 1
                    
                    yield {
                        "type": "tool_call",
                        "tool_name": tool_name,
                        "arguments": redact_sensitive_data(arguments)
                    }
                    
                    result = await self.execute_tool(tool_name, arguments)
                    
                    if '_replaced_to' in arguments:
                        yield {
                            "type": "process_info",
                            "message": f"æ”¶ä»¶äººå·²è‡ªåŠ¨æ›¿æ¢: {arguments['_replaced_to']}"
                        }
                        del arguments['_replaced_to']
                    
                    # ============ [æ–°å¢] å¤§æ•°æ®è‡ªåŠ¨æ£€æµ‹å’Œåˆ†å—å¤„ç† ============
                    result_json = json.dumps(result, ensure_ascii=False)
                    result_tokens = estimate_tokens(result_json)
                    
                    # [æ–°å¢] æ’é™¤ data_processor æœåŠ¡æœ¬èº«çš„ç»“æœï¼Œé¿å…æ— é™å¾ªç¯
                    is_dataproc_tool = tool_name.startswith("dataproc_")
                    
                    if result_tokens > MAX_TOOL_RESULT_TOKENS and not is_dataproc_tool:
                        # æ•°æ®è¿‡å¤§ï¼Œè‡ªåŠ¨åˆ†å—å¤„ç†
                        yield {
                            "type": "process_info",
                            "message": f"æ•°æ®é‡è¿‡å¤§ ({result_tokens} tokens)ï¼Œæ­£åœ¨è‡ªåŠ¨åˆ†å—å¤„ç†..."
                        }
                        
                        chunked_result = await self._auto_chunk_large_result(result_json, tool_name)
                        
                        yield {
                            "type": "tool_result",
                            "tool_name": tool_name,
                            "result": {"message": f"æ•°æ®å·²åˆ†å—ï¼Œå…± {chunked_result['total_chunks']} ä¸ªå—", "chunk_ids": chunked_result.get('chunk_ids', [])[:5]}
                        }
                        
                        messages.append({
                            "role": "tool",
                            "tool_call_id": tc_data["id"],
                            "content": json.dumps(chunked_result, ensure_ascii=False)
                        })
                    else:
                        # æ­£å¸¸å¤§å°çš„ç»“æœï¼Œç›´æ¥è¿”å›
                        yield {
                            "type": "tool_result",
                            "tool_name": tool_name,
                            "result": redact_sensitive_data(result)
                        }
                        
                        messages.append({
                            "role": "tool",
                            "tool_call_id": tc_data["id"],
                            "content": result_json
                        })
                    # ============ [æ–°å¢ç»“æŸ] ============
                
                continue
            
            # ä¼°ç®—å®Œæˆ token æ•°å¹¶è®¡ç®—è€—æ—¶
            import time
            completion_tokens = estimate_tokens(collected_content)
            self.token_stats["completion_tokens"] += completion_tokens
            self.token_stats["total_tokens"] = self.token_stats["prompt_tokens"] + self.token_stats["completion_tokens"]
            self.token_stats["elapsed_seconds"] = time.time() - self.token_stats.get("start_time", time.time())
            
            yield {
                "type": "complete",
                "think": thinking_content,
                "say": say_content,
                "token_stats": self.token_stats.copy()
            }
            break
        else:
            # è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œç”Ÿæˆæœ€ç»ˆæ€»ç»“
            if tools:
                messages.append({
                    "role": "user",
                    "content": "è¯·æ ¹æ®ä¸Šè¿°å·¥å…·è°ƒç”¨ç»“æœï¼Œç®€è¦æ€»ç»“å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"
                })
                try:
                    self.token_stats["api_calls"] += 1
                    final_response = await self.client.chat.completions.create(
                        model=self.model,
                        messages=messages,
                        temperature=self.temperature,
                        max_tokens=self.max_tokens,
                        stream=True
                    )
                    final_content = ""
                    async for chunk in final_response:
                        if chunk.choices and chunk.choices[0].delta.content:
                            content = chunk.choices[0].delta.content
                            final_content += content
                            yield {"type": "say", "content": content, "partial": True}
                    
                    # æ›´æ–° token ç»Ÿè®¡
                    import time
                    self.token_stats["completion_tokens"] += estimate_tokens(final_content)
                    self.token_stats["total_tokens"] = self.token_stats["prompt_tokens"] + self.token_stats["completion_tokens"]
                    self.token_stats["elapsed_seconds"] = time.time() - self.token_stats.get("start_time", time.time())
                    yield {"type": "complete", "think": "", "say": final_content, "token_stats": self.token_stats.copy()}
                except Exception as e:
                    logger.error(f"ç”Ÿæˆæœ€ç»ˆæ€»ç»“å¤±è´¥: {e}")
                    import time
                    self.token_stats["total_tokens"] = self.token_stats["prompt_tokens"] + self.token_stats["completion_tokens"]
                    self.token_stats["elapsed_seconds"] = time.time() - self.token_stats.get("start_time", time.time())
                    yield {"type": "complete", "think": "", "say": "ï¼ˆå·²è¾¾åˆ°æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°ï¼‰", "token_stats": self.token_stats.copy()}
    
    async def _sync_chat_with_tools(self, prompt: str, skills: Optional[List[str]] = None) -> Dict[str, Any]:
        result = {"type": "complete", "think": "", "say": "", "tool_calls": []}

        async for chunk in self._stream_chat_with_tools(prompt, skills=skills):
            if chunk.get("type") == "tool_call":
                result["tool_calls"].append({
                    "name": chunk.get("tool_name"),
                    "arguments": chunk.get("arguments")
                })
            elif chunk.get("type") == "tool_result":
                for tc in result["tool_calls"]:
                    if tc["name"] == chunk.get("tool_name"):
                        tc["result"] = chunk.get("result")
            elif chunk.get("type") == "think" and chunk.get("partial"):
                result["think"] += chunk.get("content", "")
            elif chunk.get("type") == "say" and chunk.get("partial"):
                result["say"] += chunk.get("content", "")
            elif chunk.get("type") == "complete":
                if chunk.get("think"):
                    result["think"] = chunk.get("think")
                if chunk.get("say"):
                    result["say"] = chunk.get("say")
        
        return result


class PromptPreprocessor:
    def __init__(self, web_root: str = "web"):
        self.web_root = Path(web_root)
        self.http_client = httpx.AsyncClient(timeout=30.0)
    
    async def process(self, prompt: str) -> str:
        pattern = r'@\{([^}]+)\}'
        
        async def replace_match(match):
            expression = match.group(1).strip()
            return await self._evaluate_expression(expression)
        
        matches = list(re.finditer(pattern, prompt))
        if not matches:
            return prompt
        
        result = prompt
        for match in reversed(matches):
            replacement = await self._evaluate_expression(match.group(1).strip())
            result = result[:match.start()] + replacement + result[match.end():]
        
        return result
    
    async def _evaluate_expression(self, expression: str) -> str:
        if expression.startswith('file(') and expression.endswith(')'):
            file_path = expression[5:-1].strip().strip('"\'')
            return await self._load_file(file_path)
        
        elif expression.startswith('api(') and expression.endswith(')'):
            url = expression[4:-1].strip().strip('"\'')
            return await self._call_api(url)
        
        elif expression.startswith('browser(') and expression.endswith(')'):
            url = expression[8:-1].strip().strip('"\'')
            return await self._browser_fetch(url)
        
        return f"[æœªçŸ¥è¡¨è¾¾å¼: {expression}]"
    
    async def _load_file(self, file_path: str) -> str:
        try:
            full_path = self.web_root / file_path
            if full_path.exists():
                with open(full_path, 'r', encoding='utf-8') as f:
                    return f.read()
            return f"[æ–‡ä»¶ä¸å­˜åœ¨: {file_path}]"
        except Exception as e:
            return f"[æ–‡ä»¶è¯»å–é”™è¯¯: {e}]"
    
    async def _call_api(self, url: str) -> str:
        try:
            response = await self.http_client.get(url)
            response.raise_for_status()
            return response.text
        except Exception as e:
            return f"[APIè°ƒç”¨é”™è¯¯: {e}]"
    
    async def _browser_fetch(self, url: str) -> str:
        try:
            from playwright.async_api import async_playwright
            
            async with async_playwright() as p:
                browser = await p.chromium.launch(headless=True)
                page = await browser.new_page()
                await page.goto(url, wait_until='networkidle')
                content = await page.content()
                await browser.close()
                return content
        except Exception as e:
            logger.warning(f"Browser fetchå¤±è´¥ï¼Œé™çº§åˆ°httpx: {e}")
            try:
                response = await self.http_client.get(url)
                return response.text
            except Exception as e2:
                return f"[æµè§ˆå™¨è·å–é”™è¯¯: {e2}]"
    
    async def close(self):
        await self.http_client.aclose()
